本指南根据您的简历内容（莫广智-个人简历）及您面试 AI 相关业务公司的特定需求，为您整理了一份全面的面试问题清单及参考答案。问题涵盖了**综合能力**、**前端架构与性能优化**、**AI Agent 与模型应用**、**AI Coding 竞品与业务逻辑**、**工程化与全栈**五个核心领域，旨在帮助您系统性地回顾项目经验，突出个人在 AI 浪潮下的核心竞争力。

## 一、 综合与行为问题 (General & Behavioral)

这类问题旨在考察您的职业发展、自我认知和软技能。

| 编号 | 问题 | 考察要点 | 参考答案要点 |
| --- | --- | --- | --- |
| :--- | :--- | :--- | :--- |
| **Q1** | 请介绍一下您 7 年一线互联网大厂的工作经验，以及您在前端领域的成长路径。 | 职业发展、角色转变、技术广度与深度 | 突出从腾讯云（从 0 到 1 搭建 PLM 系统）到字节跳动（亿级 PV 核心业务架构重构、AI Agent 探索）的转变。强调从**基础开发**到**技术架构师/专家**的角色升级，体现**广度**（全栈、工程化）和**深度**（架构、性能、AI）。 |
| **Q2** | 您的求职意向是“资深前端/全栈开发专家、leader”，您认为您最大的优势和挑战分别是什么？ | 自我认知、核心竞争力、职业规划 | **优势**：**架构设计能力**（三层架构、DDD）、**性能优化实战经验**（FMP P90 优化 30%+）、**AI 工程化落地经验**（AI Coding 提效、Agent 探索）。**挑战**：如何将 AI 提效经验推广到更广范围、如何平衡技术深度和团队管理。 |
| **Q3** | 您在字节跳动负责 15+ 成员团队的技术 OKR 制定，请分享一个您如何通过技术手段影响业务目标达成的案例。 | 领导力、目标管理、技术驱动业务 | 结合 CapCut 推荐首页重构项目。OKR 目标是“提升用户体验和研发效率”。通过**架构重构**和**性能优化**，直接将 FMP P90 优化 30%+，带来了**推荐导出渗透率**的正向增长（业务收益），同时**研发效率提升 30%**（团队效率）。 |

## 二、 前端架构与性能优化 (Architecture & Performance)

这类问题基于 CapCut 推荐首页重构项目，考察您在复杂系统架构和极致性能优化方面的能力。

| 编号 | 问题 | 考察要点 | 参考答案要点 |
| --- | --- | --- | --- |
| :--- | :--- | :--- | :--- |
| **Q4** | 在 CapCut 推荐首页重构中，您是如何设计 **UI/逻辑彻底分离（三层架构）**的？它解决了哪些具体问题？ | 架构设计、解耦能力、可维护性 | **三层架构**：UI 层（视图）、逻辑层（业务逻辑）、领域层（通用能力）。解决了**代码耦合严重**、**业务逻辑混乱**、**可维护性差**的问题。通过解耦，使 UI 变化不影响核心逻辑，逻辑变化不影响通用能力。 |
| **Q5** | 您提到了引入 **DDD（领域驱动设计）**思想，具体是如何在前端项目中应用的？ | DDD 思想、领域建模、通用能力抽象 | 解释 DDD 在前端的体现：将缓存管理、实验配置、数据请求、异常处理等通用能力抽象并下沉到**领域服务**中。这解决了**底层能力重复建设**和**管理混乱**的问题，使业务逻辑更聚焦于领域模型。 |
| **Q6** | CapCut 性能优化中，您认为 **FMP P90 从 15.5s 优化至 10.5s** 的最大贡献点是什么？请详细说明 **数据预请求 (Prefetch)** 的实现细节。 | 性能分析、优化策略、跨端协同 | **最大贡献点**：是**系统性优化**的结果，其中 **数据预请求** 和 **首屏可见渲染优先** 是关键。**Prefetch 细节**：与客户端协同，将核心 FeedList 数据的网络请求提前至 App 冷启动阶段，前端通过 **JSB**（JavaScript Bridge）直接获取预请求结果，实现接口**“零等待”**。 |

## 三、 专项增强：AI Agent 与模型应用 (Advanced AI Agent & LLM)

这类问题基于您的“视频编辑 Agent 项目探索”经验，旨在考察您对 Agent 架构、工具调用、指令执行和 LLM 交互模式的深度理解。

| 编号 | 问题 | 考察要点 | 参考答案要点 |
| --- | --- | --- | --- |
| :--- | :--- | :--- | :--- |
| **Q7** | 请详细阐述您在视频编辑 Agent 项目中设计的 **“原子能力抽象与沙箱执行”** 机制。这与业界主流的 **Function Calling/Tool Use** 机制有何异同？ | Agent 工具调用、指令执行、沙箱安全 | **机制**：将剪辑功能抽象为 80+ 原子能力，通过 LLM 生成指令序列，由前端**安全的 JavaScript 沙箱**解释执行。**异同**：**相同点**：本质都是将 LLM 的能力从文本生成扩展到外部工具调用。**不同点**：主流 Function Calling 是 LLM 输出 JSON 格式的函数调用，由后端或应用层执行；您的方案是 LLM 输出**指令序列**，由**前端沙箱**执行，更灵活、更贴近前端业务逻辑，但对沙箱的**安全性**和**指令解析器**的**鲁棒性**要求更高。 |
| **Q8** | 您提到 Agent 架构是“应用/逻辑/核心三层分离”，请问“核心层”具体包含了哪些与 LLM 交互的关键逻辑？如何确保指令执行的**幂等性**和**可回溯性**？ | Agent 架构设计、状态管理、事务控制 | **核心层**：应包含 **会话管理**、**指令解析器**、**原子能力注册与调度**、**状态同步**（与编辑器状态同步）。**幂等性/可回溯性**：通过**指令序列**（而非最终状态）作为核心数据，确保每条指令执行结果可预测。通过**事务日志**记录指令执行前后的状态快照，实现回溯（Undo/Redo）和重试（Retry）。 |
| **Q9** | 在 Agent 项目中，您是如何解决 LLM 带来的**“幻觉”**和**“指令错误”**问题的？作为前端负责人，您有哪些工程化手段来保障指令的**可靠性**？ | LLM 局限性、错误处理、工程鲁棒性 | **解决手段**：1. **Prompt Engineering**：在 System Prompt 中严格约束 LLM 输出格式和指令集。2. **指令校验**：在沙箱执行前，对 LLM 输出的指令序列进行**结构化校验**和**语义校验**。3. **错误捕获**：在沙箱内捕获执行错误，并将其作为**上下文**反馈给 LLM 进行**自我修正**（Self-Correction/ReAct 思想）。 |
| **Q10** | 作为一个前端/全栈专家，您如何看待 **LLM 的训练、微调（Fine-tuning）**与您的工作边界？您认为前端团队应该如何参与到模型迭代中？ | 技术边界、跨职能协作、模型应用 | **边界**：前端不直接参与模型训练，但应深度参与**模型应用**和**数据反馈**。**参与方式**：1. **数据标注/收集**：收集用户与 Agent 的高质量交互数据（指令、执行结果），用于模型微调。2. **模型评估**：设计前端 A/B Test 框架，评估不同模型版本在真实用户场景下的**指令准确率**和**用户满意度**。3. **模型路由**：在 BFF 层实现模型路由，根据用户、场景、成本等因素动态选择调用不同的模型。 |

## 四、 专项增强：AI Coding 竞品与业务逻辑 (AI Coding Competitors & Business)

这类问题基于您的“剪 C 生态 AI 提效”经验，考察您对 AI 编程工具的行业认知、业务逻辑和落地策略。

| 编号 | 问题 | 考察要点 | 参考答案要点 |
| --- | --- | --- | --- |
| :--- | :--- | :--- | :--- |
| **Q11** | 请对比分析 **Cursor、Windsurf、Trae** 这三款 AI Coding 竞品的优劣势，并说明您在“剪 C 生态”中沉淀的 **AI Skill** 机制与它们有何异同？ | 竞品分析、技术洞察、差异化 | **对比**：**Cursor**：原生 IDE 体验强，上下文理解深。**Windsurf**：轻量级 VS Code 扩展，Agentic Flow 优秀。**Trae**：字节跳动出品，中文优化，激进的免费策略。**AI Skill 机制**：您的 Skill 机制更偏向**企业内部知识的封装**（如“服务端接口文档一键生成前端请求代码”），是**场景化**、**私有化**的 Agent，解决了**企业内部非标场景**的上下文缺失问题，这是通用竞品难以做到的。 |
| **Q12** | 您是如何通过 **“上下文工程建设”** 解决 Lynx 等复杂场景下的 AI 生成代码准确率问题的？请举例说明。 | 上下文管理、RAG 应用、工程知识库 | **上下文工程**：通过沉淀**项目 Rules** 与 **README** 构建**工程知识库**。**解决问题**：Lynx 等非标准框架或历史遗留代码，AI 缺乏训练数据。通过将**项目特有的依赖关系**、**开发规范**作为上下文喂给 LLM，显著提升了 AI 在这些特殊场景下的代码准确率和可用性。**举例**：告知 AI 特定组件的命名规范、数据流向等。 |
| **Q13** | 您在项目中推动了 **18 个全栈需求**的交付，请问您是如何利用 AI 赋能全栈开发，并确保跨栈开发质量的？ | 全栈能力、AI 赋能、质量保障 | **AI 赋能**：利用 AI 辅助快速学习后端/客户端技术，如**一键生成 CRUD 接口代码**、**数据库 Schema 迁移脚本**等。**质量保障**：1. **Code Review**：重点关注 AI 生成的后端代码的**安全性**和**性能**。2. **全链路测试**：通过 E2E 测试确保前端、BFF、后端的数据流转正确。3. **分享实践**：沉淀全栈开发实践，提升团队整体质量意识。 |

## 五、 工程化与全栈技术 (Engineering & Full Stack)

这类问题基于您的腾讯云经历和个人技能，考察您的工程化能力和全栈视野。

| 编号 | 问题 | 考察要点 | 参考答案要点 |
| --- | --- | --- | --- |
| :--- | :--- | :--- | :--- |
| **Q14** | 请详细介绍您在腾讯云 PLM 子系统项目中，从 0 到 1 主导前端架构设计与研发的经验。 | 0 到 1 经验、架构选型、技术基建 | **背景**：服务 4 万+ 云产品、50 万+ 物料的核心经营管理平台。**架构**：微前端架构、Node.js 接入层（BFF）、自动化部署流水线。**挑战**：复杂表单的渲染性能优化、大规模物料的管理。突出您作为**前端负责人**的决策和落地能力。 |
| **Q15** | 您在 Node.js (API 网关, BFF) 方面有经验，请说明您在项目中是如何定位和使用 BFF 层的，它解决了哪些问题？ | BFF 架构、服务端能力、前后端职责划分 | **定位**：BFF (Backend For Frontend) 作为**接入层**，介于前端和多个后端服务之间。**作用**：1. **数据聚合与裁剪**，满足前端特定需求，减少网络请求。2. **协议转换**，处理前后端差异。3. **安全与认证**。解决了**前端过度依赖后端**、**接口冗余**和**性能优化**的问题。 |

## 六、 总结与展望

最后，准备一个有力的总结，突出您的核心价值。

| 编号 | 问题 | 考察要点 | 参考答案要点 |
| --- | --- | --- | --- |
| :--- | :--- | :--- | :--- |
| **Q16** | 您认为您能为我们团队带来哪些独特的价值？ | 核心价值、不可替代性 | **核心价值**：**“架构设计 + 极致性能 + AI 工程化落地”** 的复合能力。您不仅能解决现有复杂系统的架构和性能问题（CapCut 重构），还能引领团队探索下一代技术方向（AI Agent、全栈赋能），是**能打硬仗、能带团队、能看未来**的专家。 |
| **Q17** | 您对未来的技术发展趋势，尤其是前端与 AI 结合的领域，有什么看法和规划？ | 技术前瞻性、个人规划 | **看法**：AI Agent 将成为新的交互范式，前端将从“渲染”转向“指令执行”和“上下文管理”。**规划**：继续深耕 **Agent 架构**、**Prompt Engineering** 和 **上下文工程**，探索更高效的 **MCP**（Model Context Protocol）应用，将 AI 提效经验从团队推广到行业。 |